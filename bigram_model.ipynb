{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIaFZXU2Q9Fe",
        "outputId": "5efc0f4c-a767-4727-aa64-d7b9582df59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-04 13:48:21--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2026-01-04 13:48:21 (7.29 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download Tiny Shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the text file\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(\"Total characters in dataset:\", len(text))\n",
        "print(\"\\nSample text:\\n\")\n",
        "print(text[:500])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTlFwnzTRCic",
        "outputId": "71a245de-0b14-4ea5-f15f-3d869984b9ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters in dataset: 1115394\n",
            "\n",
            "Sample text:\n",
            "\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique characters\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "print(\"Vocabulary size:\", vocab_size)\n",
        "print(\"Characters:\", chars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrAyWq4ERIx9",
        "outputId": "3cc40d40-7cb3-4db0-c77e-e03f7e91d719"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 65\n",
            "Characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Character to index and index to character mapping\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n"
      ],
      "metadata": {
        "id": "yuVyp-_jRJ69"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Initialize bigram count matrix\n",
        "bigram_counts = torch.zeros((vocab_size, vocab_size), dtype=torch.int32)\n",
        "\n",
        "# Count bigrams\n",
        "for ch1, ch2 in zip(text[:-1], text[1:]):\n",
        "    i = stoi[ch1]\n",
        "    j = stoi[ch2]\n",
        "    bigram_counts[i, j] += 1\n",
        "\n",
        "bigram_counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLUY1T3CRMlI",
        "outputId": "ba167a39-d2c6-422a-9f94-6c6df3c619b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7223,     0,     0,  ...,     0,    66,     0],\n",
              "        [    2,    16,     0,  ...,     0,  5140,    10],\n",
              "        [ 1229,   879,     0,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    4,    36,     0,  ...,     0,     2,     0],\n",
              "        [  396, 10283,   151,  ...,     0,     0,     0],\n",
              "        [    0,     2,     1,  ...,     0,     5,    11]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert counts to probabilities\n",
        "bigram_probs = bigram_counts.float()\n",
        "bigram_probs = bigram_probs / bigram_probs.sum(dim=1, keepdim=True)\n"
      ],
      "metadata": {
        "id": "qrRL9U2-SAbS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check probability sum of one row\n",
        "bigram_probs[stoi['a']].sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tATNbJhVSFDE",
        "outputId": "43126488-a42d-4fae-a13f-21af429a8bc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_text(start_char, length=500):\n",
        "    current_char = start_char\n",
        "    output = current_char\n",
        "\n",
        "    for _ in range(length):\n",
        "        i = stoi[current_char]\n",
        "        probs = bigram_probs[i]\n",
        "\n",
        "        # Sample next character\n",
        "        next_index = torch.multinomial(probs, num_samples=1).item()\n",
        "        next_char = itos[next_index]\n",
        "\n",
        "        output += next_char\n",
        "        current_char = next_char\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "uMD6S7RMSaWk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with a random character\n",
        "start_char = random.choice(chars)\n",
        "\n",
        "generated_text = generate_text(start_char, length=600)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7AxttcYScEE",
        "outputId": "1ec8c67a-e284-495a-c7c5-7833477a78ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enen ind s, d wndobrelly s ir laror he le\n",
            "\n",
            "BRI we qu hinthan ok m wheliry!\n",
            "AUMy cail s p semprker'd menoulotha m, t mave fffrakelllouegurrdwichefo mmat oe cll we te g bler oominene s yofreasuted cthikso:\n",
            "\n",
            "Tht VISerdonte ine:\n",
            "D witt Poppe s y pecr fe f manty he-\n",
            "\n",
            "f kimale,\n",
            "Peruasse't m, rveld\n",
            "\n",
            "Malleanoway he wo havo and:\n",
            "NGavelind d tern bjurd huts n orld bldouthis trast meher betang serr Juces my memeitil;\n",
            "Buthaletf CI VI s f s.\n",
            "cirin h\n",
            "\n",
            "\n",
            "ONIZo merantrik, t\n",
            "Whole animofe Doullfry. dorm cor 'sangrdowesullof\n",
            "I sthat lometousts, her.\n",
            "GLome; w h RI wameangma othes; s'TI chus l eacance Tist, tourot \n"
          ]
        }
      ]
    }
  ]
}